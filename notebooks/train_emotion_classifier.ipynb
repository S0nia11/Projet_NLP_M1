{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11bcd544-0440-4a2c-bc4a-c6b57cd9b0e1",
   "metadata": {},
   "source": [
    "## Ce fichier consiste à :\n",
    "- Chargement des données\n",
    "- Tokenisation avec Hugging Face\n",
    "- Conversion en Dataset Hugging Face\n",
    "- Fine-tuning de DistilBERT\n",
    "- Évaluation (accuracy, F1)\n",
    "- Sauvegarde du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ee82214-be08-4a61-8081-0540e1f1a8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "473f7916-9b33-47bd-82d6-c598852e99aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/goemotions_clean.csv')\n",
    "\n",
    "texts = df['text_clean'].tolist()\n",
    "labels = df.drop(columns=['text_clean']).values\n",
    "X_train, X_val, y_train, y_val = train_test_split(texts, labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe601ac-77ec-42e7-a919-b26504170347",
   "metadata": {},
   "source": [
    "### Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ccfcff0-8ac2-4261-9248-ea3ca4977e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "def tokenize_batch(texts):\n",
    "    return tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9299d14d-e972-48f1-9ede-8b6b9e82cab2",
   "metadata": {},
   "source": [
    "### Créer un Dataset Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd393609-efd0-4a57-b65c-afc802cd119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "       \n",
    "        texts = [str(x) for x in texts]\n",
    "        self.encodings = tokenizer(texts, padding=True, truncation=True, max_length=128)\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx]).float()  # multi-label = float\n",
    "        return item\n",
    "\n",
    "train_dataset = EmotionDataset(X_train, y_train, tokenizer)\n",
    "val_dataset   = EmotionDataset(X_val, y_val, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da71790e-7f1d-496a-83c2-571d6237df0b",
   "metadata": {},
   "source": [
    "### Fine-tuning avec DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ba2f0b7-101f-4a2a-869a-8d1f216af67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = y_train.shape[1]\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=num_labels,\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1e2fbd-549b-403b-9d11-ac4407e0f5c1",
   "metadata": {},
   "source": [
    "### Sauvegarde du modèle fine-tuné et du tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d15a60ac-530f-4eab-861f-3b0afad7d2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../models/emotion_distilbert\\\\tokenizer_config.json',\n",
       " '../models/emotion_distilbert\\\\special_tokens_map.json',\n",
       " '../models/emotion_distilbert\\\\vocab.txt',\n",
       " '../models/emotion_distilbert\\\\added_tokens.json',\n",
       " '../models/emotion_distilbert\\\\tokenizer.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"../models/emotion_distilbert\", safe_serialization=False)\n",
    "tokenizer.save_pretrained(\"../models/emotion_distilbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d617dbd3-2bd0-48fe-a062-0c4905225bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_tps)",
   "language": "python",
   "name": "my_tps"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
